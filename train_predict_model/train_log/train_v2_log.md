# train_and_save_model_v2.py

## ğŸ¯ ì£¼ìš” ë³€ê²½ ì‚¬í•­
1. Bidirectional LSTM + Attention - ì–‘ë°©í–¥ í•™ìŠµìœ¼ë¡œ íŒ¨í„´ íŒŒì•… í–¥ìƒ
2. ë°ì´í„° ì¦ê°• 15ë°° - 111ê°œ â†’ ì•½ 1,776ê°œ (ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„°)
3. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ - í•™ìŠµì´ ì •ì²´ë˜ë©´ ìë™ìœ¼ë¡œ í•™ìŠµë¥  ê°ì†Œ
4. ë°°ì¹˜ ì‚¬ì´ì¦ˆ 16 - ë” ì•ˆì •ì ì¸ í•™ìŠµ
5. Patience 30 - ì¶©ë¶„í•œ í•™ìŠµ ì‹œê°„ ì œê³µ
6. ê°œì„ ëœ ë°ì´í„° ì¦ê°• ì „ëµ (4ê°€ì§€)
   - ì‹œê°„ì  ìŠ¤ì¼€ì¼ë§(ìˆ˜ì–´ ë™ì‘ì˜ ì†ë„ ë³€í™”)
   - ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€(ì† ë–¨ë¦¼ì´ë‚˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì˜¤ì°¨)
   - ìœ„ì¹˜ ì´ë™(ì¹´ë©”ë¼ ì•ì—ì„œ ì•½ê°„ ì™¼ìª½/ì˜¤ë¥¸ìª½/ìœ„/ì•„ë˜ë¡œ ì´ë™)
   - ìŠ¤ì¼€ì¼ ë³€í™”(ì¹´ë©”ë¼ì™€ì˜ ê±°ë¦¬ ë³€í™”)
7. ê°œì„ ëœ ì¦ê°•ì˜ ì¥ì :
  - ê° ì¦ê°•ì„ ê°œë³„ì ìœ¼ë¡œ ì ìš© (í•œ ë²ˆì— í•˜ë‚˜ì”©)
  - ë” ì‘ê³  í˜„ì‹¤ì ì¸ ë³€í™” ë²”ìœ„
  - ìˆœí™˜ ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ì¦ê°•ì´ ê· ë“±í•˜ê²Œ ì ìš©
  - ì›ë³¸ ë°ì´í„°ì˜ ë³¸ì§ˆì  íŠ¹ì„± ë³´ì¡´


---

## ğŸš¨ ì‹¬ê°í•œ ê³¼ì í•©(Overfitting) ë¬¸ì œ ë°œìƒ
> 100% ì •í™•ë„ëŠ” ì¢‹ì€ ê²Œ ì•„ë‹ˆë¼ ë‚˜ìœ ì‹ í˜¸

## ë¬¸ì œ ë¶„ì„

### 1ï¸âƒ£ ëª…ë°±í•œ ê³¼ì í•© ì¦ê±°
```text
Epoch 7: val_accuracy 100%, val_loss 0.0177
Epoch 8-50: ê³„ì† 100% ìœ ì§€
í…ŒìŠ¤íŠ¸: 100%, loss 0.0001
```
ëª¨ë¸ì´ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ê²Œ ì•„ë‹ˆë¼ ì•”ê¸°í•¨.

### 2ï¸âƒ£ ì™œ ì´ëŸ° ì¼ì´ ë°œìƒí–ˆë‚˜?
í•µì‹¬ ë¬¸ì œ: ë°ì´í„° ì¦ê°•ì´ ì˜ëª»ë¨
```text
# ì›ë³¸: 111ê°œ
# ì¦ê°•: 1776ê°œ (16ë°°)
# ë¬¸ì œ: ëª¨ë‘ ê°™ì€ 111ê°œì—ì„œ íŒŒìƒëœ ë°ì´í„°
```
- train/testë¥¼ ë‚˜ëˆ„ê¸° ì „ì— ì¦ê°•í–ˆê¸° ë•Œë¬¸ì—
- ê°™ì€ ì›ë³¸ì—ì„œ ë‚˜ì˜¨ ì¦ê°• ë°ì´í„°ê°€ train/testì— ëª¨ë‘ í¬í•¨ë¨
- ëª¨ë¸ì´ "ì•„, ì´ê±´ ID 1ë²ˆ ì˜ìƒì˜ ë³€í˜•ì´ë„¤" í•˜ê³  ì•”ê¸°

ì˜ˆì‹œ:
```text
ì›ë³¸ ì˜ìƒ A â†’ ì¦ê°• 16ê°œ ìƒì„±
  â†’ 13ê°œëŠ” trainì—, 3ê°œëŠ” testì—
  â†’ ëª¨ë¸ì´ trainì—ì„œ Aë¥¼ ë´¤ìœ¼ë‹ˆ testì˜ A ë³€í˜•ë„ ì‰½ê²Œ ë§ì¶¤
```
> ì‹¤ì œ ìƒˆë¡œìš´ ì˜ìƒì—ëŠ” ì „í˜€ ì‘ë™í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

---

## âœ… ì˜¬ë°”ë¥¸ í•´ê²° ë°©ë²•

### ë°©ë²• 1: Train/Test ë¶„ë¦¬ í›„ ì¦ê°• â­â­â­ í•„ìˆ˜

### ë°©ë²• 2: ë” ê°„ë‹¨í•œ ëª¨ë¸ ì‚¬ìš©
í˜„ì¬ ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•©ë‹ˆë‹¤ (438K íŒŒë¼ë¯¸í„° vs 1776ê°œ ìƒ˜í”Œ)

### ë°©ë²• 3: ë°ì´í„° ì¦ê°• ì¤„ì´ê¸°
15ë°° â†’ 5ë°°ë¡œ ê°ì†Œ

---

## í•™ìŠµ ë¡œê·¸

```text
python-project202508 î‚° python .\LSTM_model\train_and_save_model_v2.py

2025-10-06 00:14:16.371334: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
============================================================
ë°ì´í„° ë¡œë”© ì¤‘...
============================================================

âœ“ ì´ 111ê°œì˜ ì›ë³¸ ì‹œí€€ìŠ¤ ë¡œë“œë¨
âœ“ í´ë˜ìŠ¤ ìˆ˜: 5
âœ“ í´ë˜ìŠ¤: ['ë¬´í•œ', 'ë¯¸êµ­', 'ìˆ˜í•™', 'ì›”ì„¸', 'ì¼ìš”ì¼']

============================================================
ë°ì´í„° ì¦ê°• ì¤‘...
============================================================

âœ“ ì¦ê°• í›„: 1776ê°œ ì‹œí€€ìŠ¤ ìƒì„±
âœ“ ì¦ê°• ë°°ìˆ˜: 16.0ë°°

[í´ë˜ìŠ¤ë³„ ë°ì´í„° ê°œìˆ˜]
  ë¬´í•œ: 336ê°œ
  ë¯¸êµ­: 368ê°œ
  ìˆ˜í•™: 368ê°œ
  ì›”ì„¸: 352ê°œ
  ì¼ìš”ì¼: 352ê°œ

============================================================
ì‹œí€€ìŠ¤ íŒ¨ë”© ì¤‘...
============================================================

âœ“ íŒ¨ë”© í›„ shape: (1776, 163, 114)
âœ“ ë¼ë²¨ shape: (1776, 5)

âœ“ í›ˆë ¨ ë°ì´í„°: (1420, 163, 114)
âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: (356, 163, 114)

============================================================
Bidirectional LSTM + Attention ëª¨ë¸ ìƒì„± ì¤‘...
============================================================
2025-10-06 00:14:20.803108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer (InputLayer)             â”‚ (None, 163, 114)            â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bidirectional (Bidirectional)        â”‚ (None, 163, 256)            â”‚         248,832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 163, 256)            â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bidirectional_1 (Bidirectional)      â”‚ (None, 163, 128)            â”‚         164,352 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)                  â”‚ (None, 163, 128)            â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ attention_layer (AttentionLayer)     â”‚ (None, 128)                 â”‚          16,512 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 64)                  â”‚           8,256 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)                  â”‚ (None, 64)                  â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 5)                   â”‚             325 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 438,277 (1.67 MB)
 Trainable params: 438,277 (1.67 MB)
 Non-trainable params: 0 (0.00 B)

============================================================
ëª¨ë¸ í•™ìŠµ ì‹œì‘...
============================================================
Epoch 1/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11s 113ms/step - accuracy: 0.5176 - loss: 1.1717 - val_accuracy: 0.6761 - val_loss: 0.6958 - learning_rate: 5.0000e-04
Epoch 2/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 103ms/step - accuracy: 0.7139 - loss: 0.7052 - val_accuracy: 0.6549 - val_loss: 0.7401 - learning_rate: 5.0000e-04
Epoch 3/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 96ms/step - accuracy: 0.8099 - loss: 0.4640 - val_accuracy: 0.6972 - val_loss: 0.6522 - learning_rate: 5.0000e-04
Epoch 4/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 96ms/step - accuracy: 0.8618 - loss: 0.3605 - val_accuracy: 0.9225 - val_loss: 0.1890 - learning_rate: 5.0000e-04
Epoch 5/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 98ms/step - accuracy: 0.9243 - loss: 0.2195 - val_accuracy: 0.8310 - val_loss: 0.3268 - learning_rate: 5.0000e-04
Epoch 6/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 98ms/step - accuracy: 0.9349 - loss: 0.2003 - val_accuracy: 0.9401 - val_loss: 0.1420 - learning_rate: 5.0000e-04
Epoch 7/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 98ms/step - accuracy: 0.9665 - loss: 0.1006 - val_accuracy: 1.0000 - val_loss: 0.0177 - learning_rate: 5.0000e-04
Epoch 8/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 96ms/step - accuracy: 0.9991 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 0.0033 - learning_rate: 5.0000e-04
Epoch 9/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 97ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 5.0000e-04
Epoch 10/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 96ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0011 - learning_rate: 5.0000e-04
Epoch 11/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 97ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 7.1113e-04 - learning_rate: 5.0000e-04
Epoch 12/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 5.0869e-04 - learning_rate: 5.0000e-04
Epoch 13/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.7429e-04 - learning_rate: 5.0000e-04
Epoch 14/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 101ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 2.5589e-04 - learning_rate: 5.0000e-04
Epoch 15/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.9548e-04 - learning_rate: 5.0000e-04
Epoch 16/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 1.5056e-04 - learning_rate: 5.0000e-04
Epoch 17/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 103ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 1.1978e-04 - learning_rate: 5.0000e-04
Epoch 18/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 102ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.9913e-05 - learning_rate: 5.0000e-04
Epoch 19/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.0160e-05 - learning_rate: 5.0000e-04
Epoch 20/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 8.8714e-04 - val_accuracy: 1.0000 - val_loss: 6.6545e-05 - learning_rate: 5.0000e-04
Epoch 21/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 0.9894 - loss: 0.0506 - val_accuracy: 0.8592 - val_loss: 0.4999 - learning_rate: 5.0000e-04
Epoch 22/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 0.8275 - loss: 0.4539 - val_accuracy: 0.8908 - val_loss: 0.4297 - learning_rate: 5.0000e-04
Epoch 23/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 0.9463 - loss: 0.1707 - val_accuracy: 0.9366 - val_loss: 0.1711 - learning_rate: 5.0000e-04
Epoch 24/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 103ms/step - accuracy: 0.9877 - loss: 0.0513 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 5.0000e-04
Epoch 25/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 0.9789 - loss: 0.0586 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 5.0000e-04
Epoch 26/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 90ms/step - accuracy: 0.9791 - loss: 0.0761 
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 0.9718 - loss: 0.0885 - val_accuracy: 1.0000 - val_loss: 0.0124 - learning_rate: 5.0000e-04
Epoch 27/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 0.9991 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 2.5000e-04
Epoch 28/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 2.5000e-04
Epoch 29/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0011 - learning_rate: 2.5000e-04
Epoch 30/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 8.2293e-04 - learning_rate: 2.5000e-04
Epoch 31/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 6.6292e-04 - learning_rate: 2.5000e-04
Epoch 32/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 5.4263e-04 - learning_rate: 2.5000e-04
Epoch 33/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 98ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 4.4560e-04 - learning_rate: 2.5000e-04
Epoch 34/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 3.7839e-04 - learning_rate: 2.5000e-04
Epoch 35/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 98ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 3.2703e-04 - learning_rate: 2.5000e-04
Epoch 36/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 90ms/step - accuracy: 1.0000 - loss: 0.0019    
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 99ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 2.7154e-04 - learning_rate: 2.5000e-04
Epoch 37/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 2.4768e-04 - learning_rate: 1.2500e-04
Epoch 38/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.3253e-04 - learning_rate: 1.2500e-04
Epoch 39/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 2.1401e-04 - learning_rate: 1.2500e-04
Epoch 40/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 1.9889e-04 - learning_rate: 1.2500e-04
Epoch 41/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.8417e-04 - learning_rate: 1.2500e-04
Epoch 42/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.7208e-04 - learning_rate: 1.2500e-04
Epoch 43/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.6115e-04 - learning_rate: 1.2500e-04
Epoch 44/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.5218e-04 - learning_rate: 1.2500e-04
Epoch 45/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.3847e-04 - learning_rate: 1.2500e-04
Epoch 46/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 90ms/step - accuracy: 1.0000 - loss: 0.0012
Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 9.6843e-04 - val_accuracy: 1.0000 - val_loss: 1.2849e-04 - learning_rate: 1.2500e-04
Epoch 47/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 99ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 1.2426e-04 - learning_rate: 6.2500e-05
Epoch 48/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 100ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.2307e-04 - learning_rate: 6.2500e-05
Epoch 49/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 102ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.1951e-04 - learning_rate: 6.2500e-05
Epoch 50/300
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7s 101ms/step - accuracy: 1.0000 - loss: 8.5435e-04 - val_accuracy: 1.0000 - val_loss: 1.1527e-04 - learning_rate: 6.2500e-05
Epoch 50: early stopping
Restoring model weights from the end of the best epoch: 20.

============================================================
ëª¨ë¸ í‰ê°€ ì¤‘...

âœ“ í…ŒìŠ¤íŠ¸ ì†ì‹¤: 0.0001
âœ“ í…ŒìŠ¤íŠ¸ ì •í™•ë„: 1.0000 (100.00%)

============================================================
ëª¨ë¸ ì €ì¥ ì¤‘...
============================================================
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.

âœ“ ì €ì¥ ì™„ë£Œ!
  - ëª¨ë¸: trained_model/sign_language_model.h5
  - ì„¤ì •: trained_model/model_info.pkl

============================================================
```


