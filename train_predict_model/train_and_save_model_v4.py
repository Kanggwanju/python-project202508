import numpy as np
import pandas as pd
import os
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM
from tensorflow.keras.layers import Dense, Dropout, Concatenate, GlobalAveragePooling1D, BatchNormalization
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
import random

# ============================================================
# train_and_save_model_v4.py - CNN + BiLSTM í•˜ì´ë¸Œë¦¬ë“œ
# ============================================================
# 
# íŒŒì¼ ìœ„ì¹˜: train_predict_model/train_and_save_model_v4.py
# ì €ì¥ ìœ„ì¹˜: trained_model/trained_model_v4/
#
# ============================================================
# ì‹¤í–‰ ë°©ë²•
# ============================================================
# 
# í•™ìŠµ:
#    python .\train_predict_model\train_and_save_model_v4.py
#
# ì˜ˆì¸¡:
#    python .\train_predict_model\predict_sign_language.py --video "test.mp4" --model-dir "trained_model\trained_model_v4" --show-probs
#
# ============================================================
# CNN + BiLSTM í•˜ì´ë¸Œë¦¬ë“œë€?
# ============================================================
#
# ğŸ” CNN (Convolutional Neural Network)
#    - í•œê¸€: í•©ì„±ê³± ì‹ ê²½ë§
#    - ì—­í• : "ì‚¬ì§„ì—ì„œ íŒ¨í„´ ì°¾ê¸°"
#    - ì˜ˆì‹œ: ì† ëª¨ì–‘, ì†ê°€ë½ ê°ë„, íŒ” ìœ„ì¹˜ ë“±ì˜ "ê³µê°„ì  íŒ¨í„´" ì¸ì‹
#    - ë¹„ìœ : ê·¸ë¦¼ì„ ë³´ê³  "ì•„, ì´ê±´ ì£¼ë¨¹ ëª¨ì–‘ì´êµ¬ë‚˜" í•˜ê³  ì•Œì•„ì°¨ë¦¬ëŠ” ê²ƒ
#
# ğŸ” BiLSTM (Bidirectional Long Short-Term Memory)
#    - í•œê¸€: ì–‘ë°©í–¥ ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬
#    - ì—­í• : "ë™ì‘ì˜ ìˆœì„œ ì´í•´í•˜ê¸°"
#    - ì˜ˆì‹œ: ì†ì´ ìœ„â†’ì•„ë˜â†’ì˜†ìœ¼ë¡œ ì›€ì§ì´ëŠ” "ì‹œê°„ì  ìˆœì„œ" í•™ìŠµ
#    - ë¹„ìœ : ì˜í™”ë¥¼ ì•ë’¤ë¡œ ë³´ë©´ì„œ "ì´ ë™ì‘ì€ ì´ë ‡ê²Œ ì§„í–‰ë˜ëŠ”êµ¬ë‚˜" ì´í•´í•˜ëŠ” ê²ƒ
#
# ğŸ’¡ ì™œ ë‘˜ì„ ê²°í•©í•˜ë‚˜?
#    ìˆ˜ì–´ = ì† ëª¨ì–‘(CNN) + ì† ë™ì‘ ìˆœì„œ(BiLSTM)
#    
#    ì˜ˆ: "ìˆ˜í•™" ìˆ˜ì–´
#    - CNNì´ ì¸ì‹: "ë‘ ì†ì´ ì´ëŸ° ëª¨ì–‘ìœ¼ë¡œ ë²Œì–´ì ¸ ìˆë„¤"
#    - BiLSTMì´ ì¸ì‹: "ê·¸ ì†ì´ ì´ë ‡ê²Œ ì›€ì§ì´ëŠ”êµ¬ë‚˜"
#    - ê²°í•©: "ì•„í•˜! ì´ê±´ 'ìˆ˜í•™' ì´êµ¬ë‚˜!"
#
# ============================================================
# v3 ëŒ€ë¹„ ì£¼ìš” ê°œì„  ì‚¬í•­
# ============================================================
#
# 1. CNN ë¸Œëœì¹˜ ì¶”ê°€
#    - Conv1D ë ˆì´ì–´ë¡œ ê³µê°„ì  íŠ¹ì§• ì¶”ì¶œ
#    - ì† ëª¨ì–‘, ìœ„ì¹˜ ê´€ê³„ë¥¼ ë” ì˜ íŒŒì•…
#
# 2. BiLSTM ë¸Œëœì¹˜ ìœ ì§€
#    - ì‹œê°„ì  íŒ¨í„´ í•™ìŠµ
#    - ë™ì‘ ìˆœì„œë¥¼ ì´í•´
#
# 3. ë‘ ë¸Œëœì¹˜ ê²°í•© (Concatenate)
#    - CNNì˜ ê³µê°„ ì •ë³´ + LSTMì˜ ì‹œê°„ ì •ë³´
#    - ë” í’ë¶€í•œ íŠ¹ì§•ìœ¼ë¡œ íŒë‹¨
#
# 4. ë°ì´í„° ì¦ê°• 20ë°°ë¡œ ì¦ê°€
#    - v3: 5ë°° â†’ v4: 20ë°°
#    - ë°ì´í„° ë¶€ì¡± ë¬¸ì œ ì™„í™”
#
# 5. ê³µê²©ì  ì¦ê°• ê¸°ë²• ì¶”ê°€
#    - íšŒì „, ì¢Œìš° ë°˜ì „ ë“±
#    - ë‹¤ì–‘í•œ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
#
# 6. Class Weight ì ìš©
#    - í´ë˜ìŠ¤ ë¶ˆê· í˜• ìë™ ë³´ì •
#    - ì˜ ëª» ë§ì¶”ëŠ” í´ë˜ìŠ¤ì— ê°€ì¤‘ì¹˜
#
# 7. BatchNormalization ì¶”ê°€
#    - í•™ìŠµ ì•ˆì •í™”
#    - ìˆ˜ë ´ ì†ë„ í–¥ìƒ
#
# ============================================================
# ì˜ˆìƒ ì„±ëŠ¥
# ============================================================
#
# v3 ê²°ê³¼ (ì‹¤ì œ): 40% (ì§ì ‘ ì´¬ì˜ ì˜ìƒ)
# v4 ì˜ˆìƒ: 60-70% (ê°œì„  ëª©í‘œ)
#
# ============================================================


# ============================================================
# 1. ê³µê²©ì  ë°ì´í„° ì¦ê°• í•¨ìˆ˜
# ============================================================
def augment_sequence_aggressive(sequence: np.ndarray, num_augmentations: int = 20):
    """
    ë” ë‹¤ì–‘í•˜ê³  ê³µê²©ì ì¸ ì¦ê°•ìœ¼ë¡œ ë°ì´í„° ë¶€ì¡± ë¬¸ì œ í•´ê²°
    
    ì—¬ëŸ¬ ì¦ê°• ê¸°ë²•ì„ ë™ì‹œì— ëœë¤í•˜ê²Œ ì ìš©í•˜ì—¬
    ì‹¤ì œ ì´¬ì˜ í™˜ê²½ì˜ ë‹¤ì–‘ì„±ì„ ì‹œë®¬ë ˆì´ì…˜
    
    Args:
        sequence: ì›ë³¸ ì‹œí€€ìŠ¤ (frames, features)
        num_augmentations: ìƒì„±í•  ì¦ê°• ë°ì´í„° ê°œìˆ˜
    
    Returns:
        augmented_sequences: [ì›ë³¸ + ì¦ê°•ëœ ì‹œí€€ìŠ¤ë“¤]
    """
    augmented_sequences = [sequence]  # ì›ë³¸ í¬í•¨
    
    for i in range(num_augmentations):
        aug_seq = sequence.copy()
        
        # 1. ì†ë„ ë³€í™” (50% í™•ë¥ )
        if np.random.random() < 0.5:
            skip_factor = np.random.uniform(0.7, 1.3)
            if aug_seq.shape[0] > 10:
                new_len = int(aug_seq.shape[0] * skip_factor)
                if new_len > 5:
                    indices = np.linspace(0, aug_seq.shape[0] - 1, new_len).astype(int)
                    aug_seq = aug_seq[indices]
        
        # 2. ë…¸ì´ì¦ˆ ì¶”ê°€ (50% í™•ë¥ )
        if np.random.random() < 0.5:
            noise_level = np.random.uniform(0.002, 0.015)
            aug_seq += np.random.normal(0, noise_level, aug_seq.shape)
            aug_seq = np.clip(aug_seq, 0.0, 1.0)
        
        # 3. ìœ„ì¹˜ ì´ë™ (50% í™•ë¥ )
        if np.random.random() < 0.5:
            shift_x = np.random.uniform(-0.05, 0.05)
            shift_y = np.random.uniform(-0.05, 0.05)
            aug_seq[:, ::2] += shift_x
            aug_seq[:, 1::2] += shift_y
            aug_seq = np.clip(aug_seq, 0.0, 1.0)
        
        # 4. ìŠ¤ì¼€ì¼ ë³€í™” (50% í™•ë¥ )
        if np.random.random() < 0.5:
            scale = np.random.uniform(0.85, 1.15)
            center_x, center_y = 0.5, 0.5
            aug_seq[:, ::2] = (aug_seq[:, ::2] - center_x) * scale + center_x
            aug_seq[:, 1::2] = (aug_seq[:, 1::2] - center_y) * scale + center_y
            aug_seq = np.clip(aug_seq, 0.0, 1.0)
        
        # 5. íšŒì „ (30% í™•ë¥ ) - ìƒˆë¡œ ì¶”ê°€
        if np.random.random() < 0.3:
            angle = np.random.uniform(-10, 10)
            aug_seq = rotate_keypoints(aug_seq, angle)
        
        # 6. ì¢Œìš° ë°˜ì „ (10% í™•ë¥ ) - ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ
        if np.random.random() < 0.1:
            aug_seq[:, ::2] = 1.0 - aug_seq[:, ::2]
        
        augmented_sequences.append(aug_seq)
    
    return augmented_sequences


def rotate_keypoints(keypoints, angle_degrees):
    """
    í‚¤í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ì  ê¸°ì¤€ìœ¼ë¡œ íšŒì „
    
    ì¹´ë©”ë¼ ê°ë„ê°€ ì•½ê°„ í‹€ì–´ì§„ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
    """
    angle_rad = np.radians(angle_degrees)
    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)
    
    rotated = keypoints.copy()
    center_x, center_y = 0.5, 0.5
    
    for i in range(0, keypoints.shape[1], 2):
        x = keypoints[:, i] - center_x
        y = keypoints[:, i+1] - center_y
        
        rotated[:, i] = x * cos_a - y * sin_a + center_x
        rotated[:, i+1] = x * sin_a + y * cos_a + center_y
    
    return np.clip(rotated, 0.0, 1.0)


# ============================================================
# 2. CNN + BiLSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
# ============================================================
def build_cnn_bilstm_model(input_shape, num_classes):
    """
    CNNê³¼ BiLSTMì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
    
    êµ¬ì¡°:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Input     â”‚ (í”„ë ˆì„ë³„ í‚¤í¬ì¸íŠ¸)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â†“                 â†“                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CNN ë¸Œëœì¹˜  â”‚   â”‚ LSTM ë¸Œëœì¹˜  â”‚   â”‚ ì›ë³¸     â”‚
    â”‚  (ì† ëª¨ì–‘)   â”‚   â”‚  (ë™ì‘ìˆœì„œ)  â”‚   â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ê²°í•©     â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                          â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ë¶„ë¥˜     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Args:
        input_shape: (max_sequence_length, input_dim)
        num_classes: ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜
    
    Returns:
        compiled model
    """
    inputs = Input(shape=input_shape)
    
    # ===== CNN ë¸Œëœì¹˜: ê³µê°„ì  íŒ¨í„´ =====
    # "ê° í”„ë ˆì„ì—ì„œ ì† ëª¨ì–‘ íŠ¹ì§• ì¶”ì¶œ"
    
    # ì²« ë²ˆì§¸ Conv ë ˆì´ì–´
    x1 = Conv1D(64, kernel_size=5, padding='same', activation='relu')(inputs)
    x1 = BatchNormalization()(x1)  # í•™ìŠµ ì•ˆì •í™”
    x1 = Dropout(0.3)(x1)
    
    # ë‘ ë²ˆì§¸ Conv ë ˆì´ì–´
    x1 = Conv1D(128, kernel_size=3, padding='same', activation='relu')(x1)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(0.4)(x1)
    
    # ===== BiLSTM ë¸Œëœì¹˜: ì‹œê°„ì  íŒ¨í„´ =====
    # "í”„ë ˆì„ ìˆœì„œëŒ€ë¡œ ë™ì‘ íë¦„ ì´í•´"
    
    x2 = Bidirectional(LSTM(64, return_sequences=True))(inputs)
    x2 = Dropout(0.5)(x2)
    
    x2 = Bidirectional(LSTM(32, return_sequences=True))(x2)
    x2 = Dropout(0.5)(x2)
    
    # ===== ë‘ ë¸Œëœì¹˜ ê²°í•© =====
    # CNNì˜ ê³µê°„ ì •ë³´ + LSTMì˜ ì‹œê°„ ì •ë³´
    
    merged = Concatenate()([x1, x2]) # (None, 149, 128+64)
    
    # ì¶”ê°€ LSTMìœ¼ë¡œ ê²°í•©ëœ ì •ë³´ ì²˜ë¦¬
    x = Bidirectional(LSTM(32, return_sequences=True))(merged)
    x = Dropout(0.5)(x)
    
    # Global Average Pooling: ì‹œí€€ìŠ¤ â†’ ë²¡í„°
    x = GlobalAveragePooling1D()(x)
    
    # ===== ë¶„ë¥˜ ë ˆì´ì–´ =====
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.4)(x)
    
    outputs = Dense(num_classes, activation='softmax')(x)
    
    # ëª¨ë¸ ìƒì„±
    model = Model(inputs=inputs, outputs=outputs)
    
    # ì»´íŒŒì¼
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


# ============================================================
# 3. ë°ì´í„° ë¡œë“œ
# ============================================================
def load_and_preprocess_data(data_dir="coordinates_output"):
    """
    .npy í‚¤í¬ì¸íŠ¸ íŒŒì¼ê³¼ metadata.csv ë¡œë“œ
    """
    metadata_path = os.path.join(data_dir, "metadata.csv")
    metadata_df = pd.read_csv(metadata_path, encoding='utf-8-sig')

    X_data = []
    y_labels = []

    unique_labels = sorted(metadata_df['label'].unique())
    label_to_int = {label: i for i, label in enumerate(unique_labels)}
    int_to_label = {i: label for i, label in enumerate(unique_labels)}

    all_keypoints = []
    
    for _, row in metadata_df.iterrows():
        video_id = row['id']
        label = row['label']
        npy_path = os.path.join(data_dir, f"{video_id}_keypoints.npy")

        if os.path.exists(npy_path):
            keypoints = np.load(npy_path)
            flattened_keypoints = keypoints.reshape(keypoints.shape[0], -1)
            all_keypoints.append(flattened_keypoints)
            X_data.append(flattened_keypoints)
            y_labels.append(label_to_int[label])

    # ì „ì—­ ìŠ¤ì¼€ì¼ëŸ¬
    all_keypoints_concat = np.vstack(all_keypoints)
    global_scaler = MinMaxScaler()
    global_scaler.fit(all_keypoints_concat)
    
    X_scaled = [global_scaler.transform(x) for x in X_data]

    return X_scaled, y_labels, label_to_int, int_to_label, unique_labels, global_scaler


# ============================================================
# 4. ì‹œí€€ìŠ¤ íŒ¨ë”©
# ============================================================
def pad_sequences(sequences, max_len=None):
    """
    ëª¨ë“  ì‹œí€€ìŠ¤ë¥¼ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§ì¶¤
    """
    if max_len is None:
        max_len = max(s.shape[0] for s in sequences)
    
    padded_sequences = []
    for seq in sequences:
        if seq.shape[0] >= max_len:
            padded_sequences.append(seq[:max_len])
        else:
            padding = np.zeros((max_len - seq.shape[0], seq.shape[1]))
            padded_sequences.append(np.vstack((seq, padding)))
    return np.array(padded_sequences)


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    data_dir = "coordinates_output"
    model_dir = "trained_model/trained_model_v4"
    os.makedirs(model_dir, exist_ok=True)
    
    print("=" * 60)
    print("train_and_save_model_v4.py - CNN + BiLSTM")
    print("=" * 60)
    print("ê³µê°„ ì •ë³´(CNN) + ì‹œê°„ ì •ë³´(BiLSTM) í•˜ì´ë¸Œë¦¬ë“œ")
    print("=" * 60)
    
    # ========================================
    # Step 1: ë°ì´í„° ë¡œë“œ
    # ========================================
    print("\n" + "=" * 60)
    print("Step 1: ë°ì´í„° ë¡œë”©")
    print("=" * 60)
    X_raw, y_raw, label_to_int, int_to_label, unique_labels, global_scaler = load_and_preprocess_data(data_dir)

    if not X_raw:
        print("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    num_classes = len(unique_labels)
    print(f"ì›ë³¸ ë°ì´í„°: {len(X_raw)}ê°œ")
    print(f"í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
    print(f"í´ë˜ìŠ¤: {list(label_to_int.keys())}")
    
    # ========================================
    # Step 2: íŒ¨ë”©
    # ========================================
    print("\n" + "=" * 60)
    print("Step 2: ì›ë³¸ ë°ì´í„° íŒ¨ë”©")
    print("=" * 60)
    max_sequence_length = max(s.shape[0] for s in X_raw)
    input_dim = X_raw[0].shape[1]
    X_padded_raw = pad_sequences(X_raw, max_len=max_sequence_length)
    y_categorical_raw = to_categorical(y_raw, num_classes=num_classes)
    
    print(f"Max sequence length: {max_sequence_length}")
    print(f"Input dimension: {input_dim}")
    print(f"Padded shape: {X_padded_raw.shape}")
    
    # ========================================
    # Step 3: Train/Test ë¶„ë¦¬
    # ========================================
    print("\n" + "=" * 60)
    print("Step 3: Train/Test ë¶„ë¦¬")
    print("=" * 60)
    
    X_train_raw, X_test_raw, y_train_raw, y_test_raw, idx_train, idx_test = train_test_split(
        X_padded_raw, y_categorical_raw, range(len(X_raw)),
        test_size=0.2,
        random_state=42,
        stratify=y_raw
    )
    
    print(f"Train ì›ë³¸: {X_train_raw.shape[0]}ê°œ")
    print(f"Test ì›ë³¸: {X_test_raw.shape[0]}ê°œ")
    
    # ========================================
    # Step 4: Train ë°ì´í„° ì¦ê°• (20ë°°)
    # ========================================
    print("\n" + "=" * 60)
    print("Step 4: ê³µê²©ì  ë°ì´í„° ì¦ê°• (20ë°°)")
    print("=" * 60)
    
    X_train_list = []
    y_train_list = []
    
    for i in range(X_train_raw.shape[0]):
        seq = X_train_raw[i]
        non_zero_frames = np.any(seq != 0, axis=1)
        original_seq = seq[non_zero_frames]
        
        # 20ë°° ì¦ê°•
        augmented = augment_sequence_aggressive(original_seq, num_augmentations=20)
        
        for aug_seq in augmented:
            if aug_seq.shape[0] >= max_sequence_length:
                padded = aug_seq[:max_sequence_length]
            else:
                padding = np.zeros((max_sequence_length - aug_seq.shape[0], aug_seq.shape[1]))
                padded = np.vstack((aug_seq, padding))
            
            X_train_list.append(padded)
            y_train_list.append(y_train_raw[i])
    
    X_train_augmented = np.array(X_train_list)
    y_train_augmented = np.array(y_train_list)
    
    print(f"ì¦ê°• í›„ Train: {X_train_augmented.shape}")
    print(f"ì¦ê°• ë°°ìˆ˜: {X_train_augmented.shape[0] / X_train_raw.shape[0]:.1f}ë°°")
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬
    from collections import Counter
    train_class_counts = Counter(np.argmax(y_train_augmented, axis=1))
    test_class_counts = Counter(np.argmax(y_test_raw, axis=1))
    
    print("\n[Train í´ë˜ìŠ¤ë³„ ë°ì´í„°]")
    for class_id, count in sorted(train_class_counts.items()):
        print(f"  {int_to_label[class_id]}: {count}ê°œ")
    
    print("\n[Test í´ë˜ìŠ¤ë³„ ë°ì´í„°]")
    for class_id, count in sorted(test_class_counts.items()):
        print(f"  {int_to_label[class_id]}: {count}ê°œ")
    
    # ========================================
    # Step 5: Class Weight ê³„ì‚°
    # ========================================
    print("\n" + "=" * 60)
    print("Step 5: Class Weight ê³„ì‚°")
    print("=" * 60)
    
    y_integers = np.argmax(y_train_augmented, axis=1)
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(y_integers),
        y=y_integers
    )
    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}
    
    print("í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜:")
    for class_id, weight in class_weight_dict.items():
        print(f"  {int_to_label[class_id]}: {weight:.4f}")
    
    # ========================================
    # Step 6: ëª¨ë¸ ìƒì„±
    # ========================================
    print("\n" + "=" * 60)
    print("Step 6: CNN + BiLSTM ëª¨ë¸ ìƒì„±")
    print("=" * 60)
    input_shape = (max_sequence_length, input_dim)
    model = build_cnn_bilstm_model(input_shape, num_classes)
    model.summary()
    
    # ========================================
    # Step 7: ì½œë°± ì„¤ì •
    # ========================================
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=25,
        restore_best_weights=True,
        verbose=1
    )
    
    lr_scheduler = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=8,
        min_lr=1e-6,
        verbose=1
    )
    
    # ========================================
    # Step 8: í•™ìŠµ
    # ========================================
    print("\n" + "=" * 60)
    print("Step 8: ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    
    history = model.fit(
        X_train_augmented, y_train_augmented,
        epochs=200,
        batch_size=16,
        validation_data=(X_test_raw, y_test_raw),
        callbacks=[early_stopping, lr_scheduler],
        class_weight=class_weight_dict,  # Class Weight ì ìš©
        verbose=1
    )
    
    # ========================================
    # Step 9: í‰ê°€
    # ========================================
    print("\n" + "=" * 60)
    print("Step 9: ìµœì¢… í‰ê°€")
    print("=" * 60)
    loss, accuracy = model.evaluate(X_test_raw, y_test_raw, verbose=0)
    
    print(f"\ní…ŒìŠ¤íŠ¸ ì†ì‹¤: {loss:.4f}")
    print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    if accuracy > 0.95:
        print("\nê²½ê³ : ì •í™•ë„ê°€ 95% ì´ìƒì…ë‹ˆë‹¤.")
        print("ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë‹ˆ ì§ì ‘ ì´¬ì˜í•œ ì˜ìƒìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")
    elif accuracy >= 0.60:
        print("\nì¢‹ìŠµë‹ˆë‹¤! ì ì ˆí•œ ì •í™•ë„ì…ë‹ˆë‹¤.")
        print("ì§ì ‘ ì´¬ì˜í•œ ì˜ìƒìœ¼ë¡œ ì‹¤ì œ ì„±ëŠ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    else:
        print("\nê°œì„  í•„ìš”: ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
        print("ë” ë§ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ì¦ê°•ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
    
    # ========================================
    # Step 10: ì €ì¥
    # ========================================
    print("\n" + "=" * 60)
    print("Step 10: ëª¨ë¸ ì €ì¥")
    print("=" * 60)
    
    model.save(os.path.join(model_dir, "sign_language_model.h5"))
    
    model_info = {
        'label_to_int': label_to_int,
        'int_to_label': int_to_label,
        'max_sequence_length': max_sequence_length,
        'input_dim': input_dim,
        'num_classes': num_classes,
        'scaler': global_scaler
    }
    
    with open(os.path.join(model_dir, "model_info.pkl"), 'wb') as f:
        pickle.dump(model_info, f)
    
    print(f"ì €ì¥ ì™„ë£Œ: {model_dir}/")
    print(f"  - sign_language_model.h5")
    print(f"  - model_info.pkl")
    
    print("\n" + "=" * 60)
    print("í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)
    print("\nì˜ˆì¸¡ ì‹¤í–‰ ë°©ë²•:")
    print(f"   python .\\train_predict_model\\predict_sign_language.py --video \"test.mp4\" --model-dir \"{model_dir}\" --show-probs")
    print("\n" + "=" * 60)