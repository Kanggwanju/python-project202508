"""
ìˆ˜ì–´ ì¸ì‹ ì˜ˆì¸¡
í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ì˜ìƒ ì˜ˆì¸¡í•˜ê¸°

ì‚¬ìš©ë²•:
python predict.py --video test_video.mp4
python predict.py --url https://example.com/video.mp4
python predict.py --video_id 123  (DBì—ì„œ ê°€ì ¸ì˜¤ê¸°)
"""

import cv2
import mediapipe as mp
import numpy as np
import argparse
import joblib
from pathlib import Path
import pymysql
from dotenv import load_dotenv
import os

load_dotenv()


class CoordinateExtractor:
    """ì¢Œí‘œ ì¶”ì¶œê¸° (coordinate_extraction.pyì™€ ë™ì¼)"""
    
    def __init__(self):
        self.mp_holistic = mp.solutions.holistic
        self.holistic = self.mp_holistic.Holistic(
            static_image_mode=False,
            model_complexity=1,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.pose_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]

    def extract_from_source(self, source: str, frame_skip: int = 2) -> np.ndarray:
        """íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URLì—ì„œ ì¢Œí‘œ ì¶”ì¶œ"""
        cap = cv2.VideoCapture(source)

        if not cap.isOpened():
            raise ValueError(f"ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source}")

        frames_data = []
        frame_count = 0

        print("ì¢Œí‘œ ì¶”ì¶œ ì¤‘...", end="", flush=True)

        while True:
            success, frame = cap.read()
            if not success:
                break

            if frame_count % frame_skip == 0:
                coords = self._process_frame(frame)
                if coords:
                    frames_data.append(coords)
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if len(frames_data) % 10 == 0:
                    print(".", end="", flush=True)

            frame_count += 1

        cap.release()
        print(f" ì™„ë£Œ! ({len(frames_data)} í”„ë ˆì„)")

        if len(frames_data) == 0:
            raise ValueError("ì¢Œí‘œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return np.array(frames_data)

    def _process_frame(self, frame: np.ndarray) -> list:
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False
        results = self.holistic.process(image_rgb)

        if not hasattr(results, 'pose_landmarks') or results.pose_landmarks is None:
            return []

        keypoints = []

        # Pose (15ê°œ)
        for idx in self.pose_indices:
            lm = results.pose_landmarks.landmark[idx]
            keypoints.append([float(lm.x), float(lm.y)])

        # Left Hand (21ê°œ)
        if hasattr(results, 'left_hand_landmarks') and results.left_hand_landmarks:
            for lm in results.left_hand_landmarks.landmark:
                keypoints.append([float(lm.x), float(lm.y)])
        else:
            keypoints.extend([[0.0, 0.0]] * 21)

        # Right Hand (21ê°œ)
        if hasattr(results, 'right_hand_landmarks') and results.right_hand_landmarks:
            for lm in results.right_hand_landmarks.landmark:
                keypoints.append([float(lm.x), float(lm.y)])
        else:
            keypoints.extend([[0.0, 0.0]] * 21)

        return keypoints


class SignLanguagePredictor:
    """ìˆ˜ì–´ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, model_path="sign_language_model.pkl"):
        if not Path(model_path).exists():
            raise FileNotFoundError(
                f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}\n"
                f"ë¨¼ì € train_model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”"
            )
        
        self.model = joblib.load(model_path)
        self.extractor = CoordinateExtractor()
        print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    
    def predict(self, source: str) -> dict:
        """ì˜ìƒ ì†ŒìŠ¤ë¡œë¶€í„° ì˜ˆì¸¡"""
        # 1. ì¢Œí‘œ ì¶”ì¶œ
        keypoints = self.extractor.extract_from_source(source)
        
        # 2. ì „ì²˜ë¦¬ (í‰íƒ„í™” ë° íŒ¨ë”©)
        flattened = keypoints.flatten()
        
        # í•™ìŠµ ë°ì´í„°ì™€ ê°™ì€ ê¸¸ì´ë¡œ ë§ì¶”ê¸°
        expected_length = self.model.n_features_in_
        if len(flattened) < expected_length:
            flattened = np.pad(flattened, (0, expected_length - len(flattened)))
        else:
            flattened = flattened[:expected_length]
        
        # 3. ì˜ˆì¸¡
        prediction = self.model.predict([flattened])[0]
        probabilities = self.model.predict_proba([flattened])[0]
        
        # 4. ê²°ê³¼ ì •ë¦¬
        classes = self.model.classes_
        prob_dict = {cls: float(prob) for cls, prob in zip(classes, probabilities)}
        
        # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)
        
        return {
            "prediction": prediction,
            "confidence": float(max(probabilities)),
            "all_probabilities": sorted_probs,
            "keypoints_shape": keypoints.shape
        }


def get_video_url_from_db(video_id: int) -> str:
    """DBì—ì„œ ì˜ìƒ URL ê°€ì ¸ì˜¤ê¸°"""
    connection = pymysql.connect(
        host=os.getenv("DB_HOST", "localhost"),
        port=int(os.getenv("DB_PORT", "3306")),
        user=os.getenv("DB_USER", "root"),
        password=os.getenv("DB_PASSWORD", ""),
        database=os.getenv("DB_NAME", "test"),
        charset='utf8mb4'
    )

    try:
        with connection.cursor(pymysql.cursors.DictCursor) as cursor:
            query = "SELECT video_url FROM sign_language_data WHERE id = %s"
            cursor.execute(query, (video_id,))
            result = cursor.fetchone()
            
            if not result:
                raise ValueError(f"ID {video_id}ì— í•´ë‹¹í•˜ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤")
            
            return result['video_url']
    finally:
        connection.close()


def print_result(result: dict):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "="*50)
    print("ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼")
    print("="*50)
    print(f"\nì˜ˆì¸¡: {result['prediction']}")
    print(f"ì‹ ë¢°ë„: {result['confidence']:.2%}")
    print(f"ì¶”ì¶œëœ í”„ë ˆì„: {result['keypoints_shape'][0]}ê°œ")
    
    print("\nğŸ“Š ì „ì²´ í™•ë¥  ë¶„í¬:")
    for label, prob in result['all_probabilities']:
        bar_length = int(prob * 30)
        bar = "â–ˆ" * bar_length + "â–‘" * (30 - bar_length)
        print(f"  {label:15s} {bar} {prob:.2%}")
    
    print("="*50)


def main():
    parser = argparse.ArgumentParser(description="ìˆ˜ì–´ ì˜ˆì¸¡")
    parser.add_argument("--video", type=str, help="ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--url", type=str, help="ë¹„ë””ì˜¤ URL")
    parser.add_argument("--video_id", type=int, help="DB ë¹„ë””ì˜¤ ID")
    parser.add_argument("--model", type=str, default="sign_language_knn_model.pkl", 
                        help="ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    # ì…ë ¥ ì†ŒìŠ¤ ê²°ì •
    if args.video:
        source = args.video
        print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼: {source}")
    elif args.url:
        source = args.url
        print(f"ğŸŒ URL: {source}")
    elif args.video_id:
        print(f"ğŸ” DBì—ì„œ ID {args.video_id} ì¡°íšŒ ì¤‘...")
        source = get_video_url_from_db(args.video_id)
        print(f"âœ“ URL: {source}")
    else:
        print("âŒ ì—ëŸ¬: ì…ë ¥ ì†ŒìŠ¤ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”")
        print("\nì‚¬ìš©ë²•:")
        print("  python predict.py --video test.mp4")
        print("  python predict.py --url https://example.com/video.mp4")
        print("  python predict.py --video_id 123")
        return
    
    try:
        # ì˜ˆì¸¡ ì‹¤í–‰
        predictor = SignLanguagePredictor(args.model)
        result = predictor.predict(source)
        
        # ê²°ê³¼ ì¶œë ¥
        print_result(result)
        
    except FileNotFoundError as e:
        print(f"\nâŒ ì—ëŸ¬: {e}")
    except Exception as e:
        print(f"\nâŒ ì˜ˆì¸¡ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()